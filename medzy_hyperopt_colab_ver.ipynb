{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andreas-Lukito/Medzy_ocr/blob/main/medzy_hyperopt_colab_ver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc0HHa_PGtJZ"
      },
      "source": [
        "# Medzy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u31q74K4GtJb"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqiL40_6GtJb"
      },
      "source": [
        "This project aims to develop a machine learning model capable of interpreting doctors’ handwriting on prescriptions. By accurately detecting and translating challenging handwriting, the model will empower patients to read their prescriptions independently, making it easier for them to purchase their medications without confusion if they run out of medecine or to check if the cleric gave the correct medicine.\n",
        "\n",
        "This model will use Tensor flows' keras convolutional neural network as reference to this <a href = \"https://www.tensorflow.org/tutorials/images/cnn\">documentation</a>. The model will also be trained using this <a href=\"https://www.kaggle.com/datasets/mamun1113/doctors-handwritten-prescription-bd-dataset\">dataset</a> from kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohxPss_mGtJc"
      },
      "source": [
        "## Importing needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt\n",
        "!pip install pynvml"
      ],
      "metadata": {
        "id": "e12rEA6lGykr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33211165-4c88-42e4-86c7-0841f81b44e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (11.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vsj5gt4NGtJd"
      },
      "outputs": [],
      "source": [
        "# basic python libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# data preprocessing libraries\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# tensor flow libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Fine tuning libraries\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials, space_eval, STATUS_OK\n",
        "\n",
        "# library for gpu utilization\n",
        "import pynvml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIXSh1PiGtJe"
      },
      "source": [
        "## GPU check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NKWjbKhiGtJe",
        "outputId": "3d239fab-6925-426e-e70a-5003510144ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow is using the GPU\n",
            "GPU Name: b'NVIDIA A100-SXM4-40GB'\n"
          ]
        }
      ],
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Check if TensorFlow is using the GPU\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"TensorFlow is using the GPU\")\n",
        "\n",
        "    # Initialize the pynvml library\n",
        "    pynvml.nvmlInit()\n",
        "\n",
        "    # Get the number of GPU devices\n",
        "    num_gpus = pynvml.nvmlDeviceGetCount()\n",
        "\n",
        "    # Iterate over GPU devices\n",
        "    for i in range(num_gpus):\n",
        "        # Get the device identifier\n",
        "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
        "        # Get the full GPU name\n",
        "        gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
        "        print(\"GPU Name:\", gpu_name)\n",
        "\n",
        "    # Shutdown the pynvml library\n",
        "    pynvml.nvmlShutdown()\n",
        "else:\n",
        "    print(\"TensorFlow is not using the GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TUp8IrvTGtJf",
        "outputId": "be7e3dff-ff04-4b29-f38d-14844711a9b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gts3HoBTGtJg"
      },
      "source": [
        "## Importing the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgIT78aaHnZD",
        "outputId": "08926afc-9f1c-422f-f5c6-cf2e8c086a2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDQj0FStGtJg"
      },
      "source": [
        "### Train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiOlj8mLGtJg"
      },
      "source": [
        "#### Train Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LjoGCE_5GtJg"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/project_medzy/dataset/Training\"\n",
        "train_labels = pd.read_csv(os.path.join(train_path,\"training_labels.csv\"), delimiter = \",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eN2gisjrGtJh",
        "outputId": "be956a66-f271-44bd-da3c-0fd51dbcc308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IMAGE MEDICINE_NAME GENERIC_NAME\n",
              "0  0.png         Aceta  Paracetamol\n",
              "1  1.png         Aceta  Paracetamol\n",
              "2  2.png         Aceta  Paracetamol\n",
              "3  3.png         Aceta  Paracetamol\n",
              "4  4.png         Aceta  Paracetamol"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46835e5e-8d8e-4fb1-93cf-3633d5ecf356\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IMAGE</th>\n",
              "      <th>MEDICINE_NAME</th>\n",
              "      <th>GENERIC_NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46835e5e-8d8e-4fb1-93cf-3633d5ecf356')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46835e5e-8d8e-4fb1-93cf-3633d5ecf356 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46835e5e-8d8e-4fb1-93cf-3633d5ecf356');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bac8d187-416b-47ed-b65e-618d4e6a43d4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bac8d187-416b-47ed-b65e-618d4e6a43d4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bac8d187-416b-47ed-b65e-618d4e6a43d4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_labels",
              "summary": "{\n  \"name\": \"train_labels\",\n  \"rows\": 3120,\n  \"fields\": [\n    {\n      \"column\": \"IMAGE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3120,\n        \"samples\": [\n          \"2898.png\",\n          \"2976.png\",\n          \"2130.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEDICINE_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 78,\n        \"samples\": [\n          \"Fixal\",\n          \"Aceta\",\n          \"Flamyd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GENERIC_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Clonazepam\",\n          \"Ketoconazole (Tablet)\",\n          \"Paracetamol\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSqhKnRLGtJh"
      },
      "source": [
        "##### Encode the medecine name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "96zeKeBZGtJh"
      },
      "outputs": [],
      "source": [
        "medicine_enc = LabelEncoder()\n",
        "train_name_enc = to_categorical(medicine_enc.fit_transform(train_labels[\"MEDICINE_NAME\"]), num_classes=78)\n",
        "# train_labels[\"MEDICINE_NAME_ENC\"] = train_name_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q3GuZEFJGtJh",
        "outputId": "0f5bb391-f9d1-48ee-9654-3ce4012bf66e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(train_labels[\"MEDICINE_NAME\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9OxfOO0GtJh"
      },
      "source": [
        "after encoding there are 78 unique values/medicines since we are using label encoder, we will put them all in to a seperate column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7rFEOQaGtJh"
      },
      "source": [
        "#### Train Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dvOKyAnRGtJi"
      },
      "outputs": [],
      "source": [
        "#the image width and height to pass to the model\n",
        "img_width = 420\n",
        "img_height = np.round(img_width/3, 0).astype(\"int\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "73P5qIzjGtJi"
      },
      "outputs": [],
      "source": [
        "train_images = []\n",
        "train_files = glob.glob(\"/content/drive/MyDrive/project_medzy/dataset/Training/training_words/*.png\")\n",
        "for picture in train_files:\n",
        "    image = cv2.resize(cv2.imread(picture), (img_width, img_height))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    #since cv2 sometimes return a \"none\" type we will append the data after validating it if it is a not \"none\" type\n",
        "    if image is None:\n",
        "        print(f\"Err importing picture {picture}\")\n",
        "        continue\n",
        "\n",
        "    #apply adaptive treshold\n",
        "    image = cv2.adaptiveThreshold(image,\n",
        "                                         255, # the max value\n",
        "                                         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                         cv2.THRESH_BINARY, #the treshold we are using\n",
        "                                         41, #how many pixels to look at\n",
        "                                         10 #noise reduction\n",
        "                                         )\n",
        "\n",
        "    #sharpening the image\n",
        "    # Create the sharpening kernel\n",
        "    kernel = np.array([[-1, -1, 1],\n",
        "                        [-1,  8, -1],\n",
        "                        [-1, -2, -1]])\n",
        "\n",
        "    #increase the contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(7,7))\n",
        "    image = clahe.apply(image)\n",
        "\n",
        "    #blur the image so that the lines are more defined\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "\n",
        "    # Sharpen the image\n",
        "    image = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "    train_images.append(image)\n",
        "\n",
        "    # image = np.asarray(image) # for numpy 1.23\n",
        "    # To show the images\n",
        "    # plt.imshow(image, cmap = \"gray\")\n",
        "    # plt.show()\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "\n",
        "# Shuffling the data\n",
        "BUFFER_SIZE = len(train_images)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5YhHFS-nGtJi",
        "outputId": "d78542a3-f1d0-4110-97a1-35fa1dc21069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (140, 420)\n",
            "Labels shape: (3120, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset shape:\", train_images[0].shape)\n",
        "print(\"Labels shape:\", train_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Hu_KwEGtJi"
      },
      "source": [
        "##### Check if it is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bYXSUF7yGtJj",
        "outputId": "0f7503ad-352c-4636-cc56-014cfb07911f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       ...,\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-80c0e2dc-4ad1-441d-b1cd-f9a3a99733ac\" class=\"ndarray_repr\"><pre>ndarray (140, 420) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       ...,\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-80c0e2dc-4ad1-441d-b1cd-f9a3a99733ac button').onclick = (e) => {\n",
              "        document.querySelector('#id-80c0e2dc-4ad1-441d-b1cd-f9a3a99733ac').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-80c0e2dc-4ad1-441d-b1cd-f9a3a99733ac button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CpEyS13DGtJk",
        "outputId": "4f44dd06-7755-4f74-a370-5faa4d81b051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ac755a4fc50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(train_images[20], cmap = \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9VAkpk9gGtJk",
        "outputId": "58cdfe87-af03-48c2-c6ad-719b586ba077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example label: IMAGE                  3.png\n",
            "MEDICINE_NAME          Aceta\n",
            "GENERIC_NAME     Paracetamol\n",
            "Name: 3, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Example label:\", train_labels.iloc[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e0FkNlSGtJl"
      },
      "source": [
        "### Validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxrNpj-TGtJl"
      },
      "source": [
        "#### validation Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "asLNtGGnGtJl"
      },
      "outputs": [],
      "source": [
        "validation_path = \"/content/drive/MyDrive/project_medzy/dataset/Validation\"\n",
        "validation_labels = pd.read_csv(os.path.join(validation_path,\"validation_labels.csv\"), delimiter = \",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A59YkxHbGtJl",
        "outputId": "377ff690-efd7-4fc6-8e95-b98e8bc53463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IMAGE MEDICINE_NAME GENERIC_NAME\n",
              "0  0.png         Aceta  Paracetamol\n",
              "1  1.png         Aceta  Paracetamol\n",
              "2  2.png         Aceta  Paracetamol\n",
              "3  3.png         Aceta  Paracetamol\n",
              "4  4.png         Aceta  Paracetamol"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75bd0b1f-3c65-48c2-8c37-c1dd3ba7c43c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IMAGE</th>\n",
              "      <th>MEDICINE_NAME</th>\n",
              "      <th>GENERIC_NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75bd0b1f-3c65-48c2-8c37-c1dd3ba7c43c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75bd0b1f-3c65-48c2-8c37-c1dd3ba7c43c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75bd0b1f-3c65-48c2-8c37-c1dd3ba7c43c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f82bd8d-5e56-400e-90bc-ff622e7dd3b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f82bd8d-5e56-400e-90bc-ff622e7dd3b7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f82bd8d-5e56-400e-90bc-ff622e7dd3b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "validation_labels",
              "summary": "{\n  \"name\": \"validation_labels\",\n  \"rows\": 780,\n  \"fields\": [\n    {\n      \"column\": \"IMAGE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 780,\n        \"samples\": [\n          \"595.png\",\n          \"587.png\",\n          \"543.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEDICINE_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 78,\n        \"samples\": [\n          \"Fixal\",\n          \"Aceta\",\n          \"Flamyd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GENERIC_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Clonazepam\",\n          \"Ketoconazole (Tablet)\",\n          \"Paracetamol\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "validation_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EspgN4ZhGtJm"
      },
      "source": [
        "##### Encode the medecine name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sEGcgKSrGtJm"
      },
      "outputs": [],
      "source": [
        "validation_name_enc = to_categorical(medicine_enc.transform(validation_labels[\"MEDICINE_NAME\"]), num_classes=78)\n",
        "# validation_labels[\"MEDECINE_NAME_ENC\"] = validation_name_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c-HL34pvGtJm",
        "outputId": "4e6f9c97-8c10-4dd8-b6c3-7198a9f608d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "type(validation_name_enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "t_1xCiLsGtJn",
        "outputId": "3e1f8d1d-6251-4a2f-fcf2-714d39e897b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(validation_labels[\"MEDICINE_NAME\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLzfJuW9GtJn"
      },
      "source": [
        "#### Validation Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uT5j06V1GtJn"
      },
      "outputs": [],
      "source": [
        "validation_images = []\n",
        "validation_files = glob.glob(\"/content/drive/MyDrive/project_medzy/dataset/Validation/validation_words/*.png\")\n",
        "for picture in validation_files:\n",
        "    image = cv2.resize(cv2.imread(picture, cv2.IMREAD_GRAYSCALE), (img_width, img_height))\n",
        "\n",
        "    #since cv2 sometimes return a \"none\" type we will append the data after validating it if it is a not \"none\" type\n",
        "    if image is None:\n",
        "        print(f\"Err importing picture {picture}\")\n",
        "        continue\n",
        "    #apply adaptive treshold\n",
        "    image = cv2.adaptiveThreshold(image,\n",
        "                                         255, # the max value\n",
        "                                         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                         cv2.THRESH_BINARY, #the treshold we are using\n",
        "                                         41, #how many pixels to look at\n",
        "                                         10 #noise reduction\n",
        "                                         )\n",
        "\n",
        "    #sharpening the image\n",
        "    # Create the sharpening kernel\n",
        "    kernel = np.array([[-1, -1, 1],\n",
        "                        [-1,  8, -1],\n",
        "                        [-1, -2, -1]])\n",
        "\n",
        "    #increase the contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(7,7))\n",
        "    image = clahe.apply(image)\n",
        "\n",
        "    #blur the image so that the lines are more defined\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "\n",
        "    # Sharpen the image\n",
        "    image = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "\n",
        "    validation_images.append(image)\n",
        "    # image = np.asarray(image) # for numpy 1.23\n",
        "\n",
        "    # To show the images\n",
        "    # plt.imshow(image, cmap = \"gray\")\n",
        "    # plt.show()\n",
        "\n",
        "validation_images = np.array(validation_images)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
        "\n",
        "# Shuffling the data\n",
        "BUFFER_SIZE = len(validation_images)\n",
        "validation_dataset = validation_dataset.shuffle(BUFFER_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cUWTjKQ5GtJn",
        "outputId": "f939984f-cd69-498f-d220-b01242567f95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (780, 140, 420)\n",
            "Labels shape: (780, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset shape:\", validation_images.shape)\n",
        "print(\"Labels shape:\", validation_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRoGOtCTGtJo"
      },
      "source": [
        "##### Check if it is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nhb5q2_KGtJo",
        "outputId": "a773ea9f-5df0-4f24-9e13-ab253a507d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       ...,\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-4f892156-30df-442e-baac-5b28f5f35f3c\" class=\"ndarray_repr\"><pre>ndarray (140, 420) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       ...,\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-4f892156-30df-442e-baac-5b28f5f35f3c button').onclick = (e) => {\n",
              "        document.querySelector('#id-4f892156-30df-442e-baac-5b28f5f35f3c').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-4f892156-30df-442e-baac-5b28f5f35f3c button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "validation_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hLDzjiTjGtJo",
        "outputId": "78e6d414-a73a-4454-e12d-8fc84f14f43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ac6fc1cfc50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(validation_images[0], cmap = \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Lwc4lycfGtJv",
        "outputId": "edc2add2-10f4-4ea6-988f-69012984ba5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example label: IMAGE                  0.png\n",
            "MEDICINE_NAME          Aceta\n",
            "GENERIC_NAME     Paracetamol\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Example label:\", validation_labels.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfXPIJN2GtJv"
      },
      "source": [
        "### Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBdes_TOGtJv"
      },
      "source": [
        "#### Test Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Okmf7MGVGtJv"
      },
      "outputs": [],
      "source": [
        "test_path = \"/content/drive/MyDrive/project_medzy/dataset/Testing\"\n",
        "test_labels = pd.read_csv(os.path.join(test_path,\"testing_labels.csv\"), delimiter = \",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "U63Q5QFKGtJw",
        "outputId": "276613eb-5d7d-48d2-8734-a86cf75d199c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   IMAGE MEDICINE_NAME GENERIC_NAME\n",
              "0  0.png         Aceta  Paracetamol\n",
              "1  1.png         Aceta  Paracetamol\n",
              "2  2.png         Aceta  Paracetamol\n",
              "3  3.png         Aceta  Paracetamol\n",
              "4  4.png         Aceta  Paracetamol"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e558ece5-645d-4569-b0c3-d4bff15d8f95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IMAGE</th>\n",
              "      <th>MEDICINE_NAME</th>\n",
              "      <th>GENERIC_NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.png</td>\n",
              "      <td>Aceta</td>\n",
              "      <td>Paracetamol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e558ece5-645d-4569-b0c3-d4bff15d8f95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e558ece5-645d-4569-b0c3-d4bff15d8f95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e558ece5-645d-4569-b0c3-d4bff15d8f95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea1e5da8-6e58-4f40-8546-b9089325c819\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea1e5da8-6e58-4f40-8546-b9089325c819')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea1e5da8-6e58-4f40-8546-b9089325c819 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_labels",
              "summary": "{\n  \"name\": \"test_labels\",\n  \"rows\": 780,\n  \"fields\": [\n    {\n      \"column\": \"IMAGE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 780,\n        \"samples\": [\n          \"595.png\",\n          \"587.png\",\n          \"543.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEDICINE_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 78,\n        \"samples\": [\n          \"Fixal\",\n          \"Aceta\",\n          \"Flamyd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GENERIC_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Clonazepam\",\n          \"Ketoconazole (Tablet)\",\n          \"Paracetamol\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "test_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUvqF5rqGtJw"
      },
      "source": [
        "##### Encode the medecine name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VR6GPdVOGtJw"
      },
      "outputs": [],
      "source": [
        "test_name_enc = to_categorical(medicine_enc.transform(test_labels[\"MEDICINE_NAME\"]), num_classes=78)\n",
        "# test_labels[\"train_medecine_name_enc\"] = test_name_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Qi-SnPVhGtJw",
        "outputId": "75ef7820-ed3a-421a-f916-4575392ca1cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(test_labels[\"MEDICINE_NAME\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeJH3OkMGtJw"
      },
      "source": [
        "#### Testing Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Ikoo83DHGtJx"
      },
      "outputs": [],
      "source": [
        "test_images = []\n",
        "test_files = glob.glob(\"/content/drive/MyDrive/project_medzy/dataset/Testing/testing_words/*.png\")\n",
        "for picture in test_files:\n",
        "    image = cv2.resize(cv2.imread(picture, cv2.IMREAD_GRAYSCALE), (img_width, img_height))\n",
        "\n",
        "    #since cv2 sometimes return a \"none\" type we will append the data after validating it if it is a not \"none\" type\n",
        "    if image is None:\n",
        "        print(f\"Err importing picture {picture}\")\n",
        "        continue\n",
        "    #apply adaptive treshold\n",
        "    image = cv2.adaptiveThreshold(image,\n",
        "                                         255, # the max value\n",
        "                                         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                         cv2.THRESH_BINARY, #the treshold we are using\n",
        "                                         41, #how many pixels to look at\n",
        "                                         10 #noise reduction\n",
        "                                         )\n",
        "\n",
        "    #sharpening the image\n",
        "    # Create the sharpening kernel\n",
        "    kernel = np.array([[-1, -1, 1],\n",
        "                        [-1,  8, -1],\n",
        "                        [-1, -2, -1]])\n",
        "\n",
        "    #increase the contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(7,7))\n",
        "    image = clahe.apply(image)\n",
        "\n",
        "    #blur the image so that the lines are more defined\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "    image = cv2.GaussianBlur(image, (7,7), 20)\n",
        "\n",
        "    # Sharpen the image\n",
        "    image = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "    test_images.append(image)\n",
        "    # image = np.asarray(image) # for numpy 1.23\n",
        "\n",
        "    # To show the images\n",
        "    # plt.imshow(image, cmap = \"gray\")\n",
        "    # plt.show()\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "# Shuffling the data\n",
        "BUFFER_SIZE = len(test_images)\n",
        "test_dataset = test_dataset.shuffle(BUFFER_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Og3oHqMiGtJx",
        "outputId": "28d5292e-0388-458f-bee9-3c11579b7992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (780, 140, 420)\n",
            "Labels shape: (780, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset shape:\", test_images.shape)\n",
        "print(\"Labels shape:\", test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRICNfFMGtJx"
      },
      "source": [
        "##### Check if it is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jSLQZ0C_GtJy",
        "outputId": "a9d1a969-a849-4041-e98b-08ff7a285080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 420)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "test_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fRb5WGV8GtJy",
        "outputId": "7282c9c5-29d9-4f08-e51d-a2aa3bae3ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ac6fc0d4750>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(test_images[0], cmap = \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8VoBw2moGtJy",
        "outputId": "e26bd262-c58d-4066-f4b4-82ff2dbe0414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example label: IMAGE                  0.png\n",
            "MEDICINE_NAME          Aceta\n",
            "GENERIC_NAME     Paracetamol\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Example label:\", test_labels.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5eQd0nEGtJy"
      },
      "source": [
        "## Building the artificial neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGDLHhDLGtJz"
      },
      "source": [
        "#### Make a model create function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnyhLojVGtJz"
      },
      "source": [
        "##### Parameters for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HSymO6AFGtJz",
        "outputId": "051b331b-fd67-4efc-9cb8-de0885da45a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#number of classes to determine how many neurons are in the output layer\n",
        "num_classes = len(train_labels[\"MEDICINE_NAME\"].unique())\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aXx0BIZbGtJz",
        "outputId": "6607bbfd-e194-4cee-bc8b-590ff63da098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 420)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#the image size to determine the shape for the convolutional neural network to scan\n",
        "train_images[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKdWqFwzGtJ0"
      },
      "source": [
        "#### Custom metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5aBDZLA9GtJ0"
      },
      "outputs": [],
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return keras.backend.cast(recall, \"float16\")\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return keras.backend.cast(precision, \"float16\")\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    f1 = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "    return keras.backend.cast(f1, \"float16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM89xQcmGtJ0"
      },
      "source": [
        "#### Create a model builder for gridsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOaTV6HvGtJ0"
      },
      "source": [
        "the even filter shapes aren't recommended because it lacks the ability to devide the previous layer pixels arould the output pixel <a hre = \"https://medium.com/analytics-vidhya/how-to-choose-the-size-of-the-convolution-filter-or-kernel-size-for-cnn-86a55a1e2d15\">(Pandey, 2020)</a>.\n",
        "\n",
        "<a href = \"https://medium.com/@nerdjock/convolutional-neural-network-lesson-9-activation-functions-in-cnns-57def9c6e759\">Machine Learning in Plain English (2023)</a> The most common activation functions are \"relu\" and \"leaky relu\" therefore we would pass it in the grid search.\n",
        "\n",
        "Max pooling excells in image classification, due to how max pooling captures the most prominent features and reduce the variance of the input <a href = \"https://www.linkedin.com/advice/1/how-do-you-choose-appropriate-pooling-method-2uvmc#adaptive-pooling\">(Awad et. al, n.d.)</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qsN-QAxeGtJ1"
      },
      "outputs": [],
      "source": [
        "# Model Parameters to Grid Search\n",
        "params_space = {\n",
        "    \"filter_choice\" : hp.choice(\"filter_choice\", [32, 64, 128]),\n",
        "    \"kernel_size\" : hp.choice(\"kernel_size\", [3, 5, 7]),\n",
        "    \"n_neurons\" : hp.choice(\"n_neurons\", [128, 256, 512]),\n",
        "    \"learning_rate\": hp.uniform(\"learning_rate\",0.001,1),\n",
        "    \"activation\" : hp.choice(\"activation\",['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
        "                   'elu', 'exponential', 'softmax']),\n",
        "    \"n_conv_layers\": hp.choice(\"n_conv_layers\", [1, 3]),\n",
        "    \"n_pool_layers\": hp.choice(\"n_pool_layers\", [1, 2, 3]),\n",
        "    \"dense_optimizer\": hp.choice('optimizer', ['adam', 'sgd', 'rmsprop']),\n",
        "    \"dropout_rate\": hp.uniform(\"dropout_rate\", 0.1, 0.5)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4DXEF9E4GtJ1"
      },
      "outputs": [],
      "source": [
        "def create_model(params):\n",
        "    input_shape = (img_height, img_width, 1)\n",
        "    model = Sequential()\n",
        "    metrics = ['accuracy', recall_m, precision_m]\n",
        "\n",
        "    # Input layer\n",
        "    model.add(layers.Conv2D(\n",
        "        filters = params[\"filter_choice\"],\n",
        "        kernel_size = params[\"kernel_size\"],\n",
        "        activation= params[\"activation\"],\n",
        "        input_shape=input_shape\n",
        "    ))\n",
        "    model.add(layers.AveragePooling2D(pool_size=2))\n",
        "\n",
        "    # Convolutional layers\n",
        "    for i in range(params[\"n_conv_layers\"]):\n",
        "        model.add(layers.Conv2D(\n",
        "            filters= params[\"filter_choice\"],\n",
        "            kernel_size = params[\"kernel_size\"],\n",
        "            activation= params[\"activation\"]\n",
        "        ))\n",
        "        if i < params[\"n_pool_layers\"]:\n",
        "          model.add(layers.AveragePooling2D(pool_size=2))\n",
        "\n",
        "    # drop out layers to prevent overfitting\n",
        "    model.add(layers.Dropout(params['dropout_rate']))\n",
        "\n",
        "    # Flatten layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Intermediate dense layer\n",
        "    model.add(layers.Dense(\n",
        "        params[\"n_neurons\"],\n",
        "        activation= params[\"activation\"]\n",
        "    ))\n",
        "\n",
        "    # another drop out layers to prevent overfitting\n",
        "    model.add(layers.Dropout(params['dropout_rate']))\n",
        "\n",
        "    # Output layer (78 classes)\n",
        "    model.add(layers.Dense(78, activation=\"softmax\"))\n",
        "\n",
        "    # Optimizer selection\n",
        "    optimizer_name = params[\"dense_optimizer\"]\n",
        "    if optimizer_name == 'adam': #dynamic learning rate\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate = params[\"learning_rate\"])\n",
        "    elif optimizer_name == 'sgd': #static learning rate\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate = params[\"learning_rate\"])\n",
        "    else:\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate = params[\"learning_rate\"])\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics = metrics)\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                      mode = 'min', #to match the fmin function from hyperopt\n",
        "                                                                    #we will search for the model with the least loss\n",
        "                                                      verbose=1,\n",
        "                                                      patience=3)\n",
        "\n",
        "    model.fit(train_images, train_name_enc,\n",
        "              validation_data=(validation_images, validation_name_enc),\n",
        "              callbacks=[early_stopping])\n",
        "\n",
        "    loss, accuracy, recall, precision = model.evaluate(validation_images, validation_name_enc)\n",
        "    print(f\"validation Accuracy: {accuracy}\")\n",
        "    print(f\"validation recall: {recall}\")\n",
        "    print(f\"validation precision: {precision}\")\n",
        "    return {\n",
        "        'loss' : loss,\n",
        "        'status' :STATUS_OK,\n",
        "        'model' : model,\n",
        "        'params' : params\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEqAcWtRGtJ1"
      },
      "source": [
        "In this project, a hyperopt gridsearch will be implemented as reference to <a href = \"https://medium.com/@icaro_vazquez/neural-network-hyperparameter-optimization-with-hyperopt-f3e0cb4346c8\">(Icaro, 2024)</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "imGHOy3WGtJ1"
      },
      "outputs": [],
      "source": [
        "# initialize trials to keep the history of every trial\n",
        "trial =  Trials()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWhAK90eGtJ2"
      },
      "source": [
        "#### Start the grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0CpNxzD3GtJ2",
        "outputId": "fac71d68-637d-42fd-b0e7-b19274f3cb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:45\u001b[0m 8s/step - accuracy: 0.0000e+00 - loss: 4.4601 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 8/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0072 - loss: 21.6656 - precision_m: 5.0403e-04 - recall_m: 4.8828e-04     \n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0065 - loss: 37.5180 - precision_m: 0.0017 - recall_m: 0.0017        \n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0065 - loss: 49.3550 - precision_m: 0.0028 - recall_m: 0.0028\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0065 - loss: 58.2434 - precision_m: 0.0035 - recall_m: 0.0034\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0065 - loss: 63.6116 - precision_m: 0.0039 - recall_m: 0.0038\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0065 - loss: 67.5825 - precision_m: 0.0043 - recall_m: 0.0042\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0064 - loss: 70.0122 - precision_m: 0.0045 - recall_m: 0.0044\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0065 - loss: 71.3113 - precision_m: 0.0048 - recall_m: 0.0047\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0067 - loss: 71.9375 - precision_m: 0.0052 - recall_m: 0.0050\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0070 - loss: 72.0927 - precision_m: 0.0057 - recall_m: 0.0054\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0073 - loss: 71.9496 - precision_m: 0.0060 - recall_m: 0.0058\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0075 - loss: 71.6161 - precision_m: 0.0064 - recall_m: 0.0060\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0076 - loss: 71.3909 - precision_m: 0.0065 - recall_m: 0.0061\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 59ms/step - accuracy: 0.0076 - loss: 71.3348 - precision_m: 0.0065 - recall_m: 0.0062 - val_accuracy: 0.0128 - val_loss: 38.1597 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 40.3338 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 39.1661 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0026 - loss: 38.2925 - precision_m: 0.0025 - recall_m: 0.0025            \n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22:19\u001b[0m 14s/step - accuracy: 0.0312 - loss: 28.1714 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.0191 - loss: 242912612843520000.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.0183 - loss: 1384840530180964352.0000 - precision_m: 0.0041 - recall_m: 0.0041       \n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.0172 - loss: 1945530300012429312.0000 - precision_m: 0.0057 - recall_m: 0.0057\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0163 - loss: 2084907005289431040.0000 - precision_m: 0.0064 - recall_m: 0.0064\n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0160 - loss: 2085674739283525632.0000 - precision_m: 0.0074 - recall_m: 0.0074\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0155 - loss: 2034849539411673088.0000 - precision_m: 0.0078 - recall_m: 0.0078\n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0150 - loss: 1965231761675780096.0000 - precision_m: 0.0081 - recall_m: 0.0081\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0146 - loss: 1890389654440509440.0000 - precision_m: 0.0082 - recall_m: 0.0082\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0143 - loss: 1816162998838886400.0000 - precision_m: 0.0084 - recall_m: 0.0084\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0141 - loss: 1745049472972357632.0000 - precision_m: 0.0087 - recall_m: 0.0087\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0139 - loss: 1678031765358247936.0000 - precision_m: 0.0089 - recall_m: 0.0089\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0138 - loss: 1615371559763968000.0000 - precision_m: 0.0090 - recall_m: 0.0090\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0137 - loss: 1556993539643015168.0000 - precision_m: 0.0092 - recall_m: 0.0092\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0137 - loss: 1502663509018673152.0000 - precision_m: 0.0094 - recall_m: 0.0094\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0136 - loss: 1452088585481093120.0000 - precision_m: 0.0095 - recall_m: 0.0095\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0136 - loss: 1404963104797753344.0000 - precision_m: 0.0097 - recall_m: 0.0097\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0136 - loss: 1360989511634386944.0000 - precision_m: 0.0099 - recall_m: 0.0099\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0136 - loss: 1319887842842771456.0000 - precision_m: 0.0100 - recall_m: 0.0100\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0135 - loss: 1281401774774681600.0000 - precision_m: 0.0101 - recall_m: 0.0101\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0136 - loss: 1245298623281889280.0000 - precision_m: 0.0103 - recall_m: 0.0103\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0136 - loss: 1211368931399303168.0000 - precision_m: 0.0105 - recall_m: 0.0105\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0136 - loss: 1179424682638573568.0000 - precision_m: 0.0106 - recall_m: 0.0106\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0137 - loss: 1149297239403790336.0000 - precision_m: 0.0107 - recall_m: 0.0107\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0137 - loss: 1120835625004564480.0000 - precision_m: 0.0108 - recall_m: 0.0108\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0137 - loss: 1093904187193819136.0000 - precision_m: 0.0109 - recall_m: 0.0109\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0137 - loss: 1068381155058778112.0000 - precision_m: 0.0110 - recall_m: 0.0110\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0137 - loss: 1044156989753524224.0000 - precision_m: 0.0111 - recall_m: 0.0111\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0138 - loss: 1021133216267894784.0000 - precision_m: 0.0112 - recall_m: 0.0112\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0138 - loss: 999220636721086464.0000 - precision_m: 0.0114 - recall_m: 0.0114 \n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0139 - loss: 978338711886364672.0000 - precision_m: 0.0115 - recall_m: 0.0115\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0139 - loss: 958414599118389248.0000 - precision_m: 0.0116 - recall_m: 0.0116\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0140 - loss: 939381846683156480.0000 - precision_m: 0.0117 - recall_m: 0.0117\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0140 - loss: 921180256319045632.0000 - precision_m: 0.0118 - recall_m: 0.0118\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0141 - loss: 903754852444667904.0000 - precision_m: 0.0119 - recall_m: 0.0119\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0141 - loss: 887055401122529280.0000 - precision_m: 0.0120 - recall_m: 0.0120\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 871035929022693376.0000 - precision_m: 0.0121 - recall_m: 0.0121\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 855654379825397760.0000 - precision_m: 0.0121 - recall_m: 0.0121\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 840872133184716800.0000 - precision_m: 0.0122 - recall_m: 0.0122\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 826653454972747776.0000 - precision_m: 0.0122 - recall_m: 0.0122\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 812965634718564352.0000 - precision_m: 0.0123 - recall_m: 0.0123\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 799778367132925952.0000 - precision_m: 0.0123 - recall_m: 0.0123\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 787063752108277760.0000 - precision_m: 0.0123 - recall_m: 0.0123\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 774795813682413568.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0142 - loss: 762950500038475776.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0141 - loss: 751505614785478656.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0141 - loss: 740440335921971200.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0141 - loss: 729735353274990592.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0141 - loss: 719372662341632000.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.0141 - loss: 714326178848047104.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 129ms/step - accuracy: 0.0141 - loss: 709381537618984960.0000 - precision_m: 0.0124 - recall_m: 0.0124 - val_accuracy: 0.0128 - val_loss: 6876037632.0000 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - loss: 7542210560.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 6/25\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 6109746176.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 5739170816.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 6063217664.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 6227457536.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0026 - loss: 6329328128.0000 - precision_m: 0.0025 - recall_m: 0.0025            \n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:18\u001b[0m 9s/step - accuracy: 0.0000e+00 - loss: 27.3743 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0156 - loss: 210922373572984832.0000 - precision_m: 0.0156 - recall_m: 0.0156\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0178 - loss: 195017388121391104.0000 - precision_m: 0.0178 - recall_m: 0.0178\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0181 - loss: 172943403703599104.0000 - precision_m: 0.0181 - recall_m: 0.0181\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0194 - loss: 154473704301002752.0000 - precision_m: 0.0194 - recall_m: 0.0194\n",
            "\u001b[1m12/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0205 - loss: 133244814828240896.0000 - precision_m: 0.0205 - recall_m: 0.0205\n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0210 - loss: 117503184162783232.0000 - precision_m: 0.0210 - recall_m: 0.0210\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0213 - loss: 105396513168949248.0000 - precision_m: 0.0213 - recall_m: 0.0213\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0211 - loss: 95784032763117568.0000 - precision_m: 0.0211 - recall_m: 0.0211 \n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0209 - loss: 87951644502786048.0000 - precision_m: 0.0207 - recall_m: 0.0207\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0205 - loss: 81434212019732480.0000 - precision_m: 0.0201 - recall_m: 0.0201\n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0202 - loss: 75916708052729856.0000 - precision_m: 0.0195 - recall_m: 0.0195\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0200 - loss: 71178276793483264.0000 - precision_m: 0.0189 - recall_m: 0.0189\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0197 - loss: 67059437516357632.0000 - precision_m: 0.0183 - recall_m: 0.0183\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0194 - loss: 63442035671040000.0000 - precision_m: 0.0177 - recall_m: 0.0177\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0191 - loss: 60236619973656576.0000 - precision_m: 0.0172 - recall_m: 0.0172\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0189 - loss: 57374140234989568.0000 - precision_m: 0.0166 - recall_m: 0.0166\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0188 - loss: 54800411147632640.0000 - precision_m: 0.0161 - recall_m: 0.0161\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0187 - loss: 52472289765097472.0000 - precision_m: 0.0157 - recall_m: 0.0157\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0185 - loss: 50354952492548096.0000 - precision_m: 0.0152 - recall_m: 0.0152\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0183 - loss: 48419988121321472.0000 - precision_m: 0.0148 - recall_m: 0.0148\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0182 - loss: 46643950424948736.0000 - precision_m: 0.0144 - recall_m: 0.0144\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0180 - loss: 45007331661971456.0000 - precision_m: 0.0140 - recall_m: 0.0140\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0179 - loss: 43493733647253504.0000 - precision_m: 0.0137 - recall_m: 0.0137\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0177 - loss: 42089287931396096.0000 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0176 - loss: 40782170469433344.0000 - precision_m: 0.0130 - recall_m: 0.0130\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0174 - loss: 39562236548612096.0000 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0173 - loss: 38420733025583104.0000 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0171 - loss: 37350053513265152.0000 - precision_m: 0.0122 - recall_m: 0.0122\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0170 - loss: 36343566582153216.0000 - precision_m: 0.0119 - recall_m: 0.0119\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0168 - loss: 35395467583946752.0000 - precision_m: 0.0117 - recall_m: 0.0117\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0167 - loss: 34500628327694336.0000 - precision_m: 0.0114 - recall_m: 0.0114\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0166 - loss: 33654524065349632.0000 - precision_m: 0.0112 - recall_m: 0.0112\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0165 - loss: 33115529292021760.0000 - precision_m: 0.0110 - recall_m: 0.0110\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.0164 - loss: 32342347131912192.0000 - precision_m: 0.0108 - recall_m: 0.0108\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - accuracy: 0.0163 - loss: 32094486716743680.0000 - precision_m: 0.0108 - recall_m: 0.0108 - val_accuracy: 0.0128 - val_loss: 16316.6514 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 4.7738 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 8/25\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 4.6883 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 12175.2998 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0053 - loss: 13462.8701 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0065 - loss: 13949.2217 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:00\u001b[0m 13s/step - accuracy: 0.0000e+00 - loss: 29.1365 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0174 - loss: 388798382080.0000 - precision_m: 0.0174 - recall_m: 0.0174    \n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0160 - loss: 386647228416.0000 - precision_m: 0.0160 - recall_m: 0.0160\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0142 - loss: 360311586816.0000 - precision_m: 0.0142 - recall_m: 0.0142\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0127 - loss: 330247110656.0000 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0115 - loss: 303481421824.0000 - precision_m: 0.0115 - recall_m: 0.0115\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0105 - loss: 280430018560.0000 - precision_m: 0.0105 - recall_m: 0.0105\n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0099 - loss: 260692672512.0000 - precision_m: 0.0097 - recall_m: 0.0097\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0094 - loss: 243707658240.0000 - precision_m: 0.0090 - recall_m: 0.0090\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0091 - loss: 228972675072.0000 - precision_m: 0.0084 - recall_m: 0.0084\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0088 - loss: 216079384576.0000 - precision_m: 0.0079 - recall_m: 0.0079\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0085 - loss: 204704235520.0000 - precision_m: 0.0074 - recall_m: 0.0074\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0084 - loss: 194591784960.0000 - precision_m: 0.0070 - recall_m: 0.0070\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0083 - loss: 185539428352.0000 - precision_m: 0.0067 - recall_m: 0.0067\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0082 - loss: 177385127936.0000 - precision_m: 0.0064 - recall_m: 0.0064\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0080 - loss: 169998106624.0000 - precision_m: 0.0061 - recall_m: 0.0061\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0079 - loss: 163271835648.0000 - precision_m: 0.0058 - recall_m: 0.0058\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0078 - loss: 157118693376.0000 - precision_m: 0.0056 - recall_m: 0.0056\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0077 - loss: 151466033152.0000 - precision_m: 0.0054 - recall_m: 0.0054\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0076 - loss: 146253119488.0000 - precision_m: 0.0052 - recall_m: 0.0052\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0075 - loss: 141428736000.0000 - precision_m: 0.0050 - recall_m: 0.0050\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0075 - loss: 136949465088.0000 - precision_m: 0.0049 - recall_m: 0.0049\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0074 - loss: 132778188800.0000 - precision_m: 0.0047 - recall_m: 0.0047\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0074 - loss: 128883015680.0000 - precision_m: 0.0046 - recall_m: 0.0046\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0073 - loss: 125236387840.0000 - precision_m: 0.0044 - recall_m: 0.0044\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 121814351872.0000 - precision_m: 0.0043 - recall_m: 0.0043\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 118595977216.0000 - precision_m: 0.0042 - recall_m: 0.0042\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 115562913792.0000 - precision_m: 0.0041 - recall_m: 0.0041\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 112698990592.0000 - precision_m: 0.0040 - recall_m: 0.0040\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 109989888000.0000 - precision_m: 0.0039 - recall_m: 0.0039\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 107422900224.0000 - precision_m: 0.0038 - recall_m: 0.0038\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 104986689536.0000 - precision_m: 0.0037 - recall_m: 0.0037\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0073 - loss: 102671122432.0000 - precision_m: 0.0036 - recall_m: 0.0036\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 100467097600.0000 - precision_m: 0.0035 - recall_m: 0.0035\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 98366447616.0000 - precision_m: 0.0035 - recall_m: 0.0035 \n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 96361758720.0000 - precision_m: 0.0034 - recall_m: 0.0034\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 94446362624.0000 - precision_m: 0.0033 - recall_m: 0.0033\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 92614189056.0000 - precision_m: 0.0033 - recall_m: 0.0033\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 90859708416.0000 - precision_m: 0.0032 - recall_m: 0.0032\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 89177890816.0000 - precision_m: 0.0031 - recall_m: 0.0031\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 87564140544.0000 - precision_m: 0.0031 - recall_m: 0.0031\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 86014246912.0000 - precision_m: 0.0030 - recall_m: 0.0030\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 84524343296.0000 - precision_m: 0.0030 - recall_m: 0.0030\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 83090874368.0000 - precision_m: 0.0029 - recall_m: 0.0029\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0071 - loss: 81710571520.0000 - precision_m: 0.0029 - recall_m: 0.0029\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 80380420096.0000 - precision_m: 0.0028 - recall_m: 0.0028\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 79097626624.0000 - precision_m: 0.0028 - recall_m: 0.0028\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 77859610624.0000 - precision_m: 0.0027 - recall_m: 0.0027\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0072 - loss: 76663971840.0000 - precision_m: 0.0027 - recall_m: 0.0027\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.0073 - loss: 76082372608.0000 - precision_m: 0.0027 - recall_m: 0.0027\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 155ms/step - accuracy: 0.0073 - loss: 75512520704.0000 - precision_m: 0.0026 - recall_m: 0.0026 - val_accuracy: 0.0128 - val_loss: 4.3812 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - loss: 4.4927 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/25\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 4.4246 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/25\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 4.3958 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 6.9252e-04 - loss: 4.3873 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0039 - loss: 4.3829 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00     \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0042 - loss: 4.3828 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:37\u001b[0m 5s/step - accuracy: 0.0312 - loss: 41.1343 - precision_m: 0.0323 - recall_m: 0.0312\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0451 - loss: 398512904246132736.0000 - precision_m: 0.0458 - recall_m: 0.0451\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0383 - loss: 8405110535661551616.0000 - precision_m: 0.0388 - recall_m: 0.0383\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0329 - loss: 11574167479458463744.0000 - precision_m: 0.0333 - recall_m: 0.0329\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0289 - loss: 12321727634206621696.0000 - precision_m: 0.0292 - recall_m: 0.0289\n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0258 - loss: 12282038562978791424.0000 - precision_m: 0.0261 - recall_m: 0.0258\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0238 - loss: 11958115840366215168.0000 - precision_m: 0.0240 - recall_m: 0.0238\n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.0223 - loss: 11568518188714950656.0000 - precision_m: 0.0225 - recall_m: 0.0223\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.0212 - loss: 11172672012483035136.0000 - precision_m: 0.0214 - recall_m: 0.0212\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.0204 - loss: 10771231521088995328.0000 - precision_m: 0.0206 - recall_m: 0.0204\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0197 - loss: 10379484324205428736.0000 - precision_m: 0.0199 - recall_m: 0.0197\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0193 - loss: 10004759766343090176.0000 - precision_m: 0.0195 - recall_m: 0.0193\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0192 - loss: 9650376173594607616.0000 - precision_m: 0.0193 - recall_m: 0.0192 \n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0190 - loss: 9317312111308701696.0000 - precision_m: 0.0191 - recall_m: 0.0190\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0188 - loss: 9005228380148203520.0000 - precision_m: 0.0189 - recall_m: 0.0188\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0185 - loss: 8713128822578348032.0000 - precision_m: 0.0187 - recall_m: 0.0185\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0183 - loss: 8439727559750451200.0000 - precision_m: 0.0184 - recall_m: 0.0183\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0181 - loss: 8183646353839095808.0000 - precision_m: 0.0182 - recall_m: 0.0181\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0179 - loss: 7943521260670025728.0000 - precision_m: 0.0180 - recall_m: 0.0179\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0178 - loss: 7610436307663192064.0000 - precision_m: 0.0179 - recall_m: 0.0178\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0177 - loss: 7404721530396999680.0000 - precision_m: 0.0178 - recall_m: 0.0177\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0176 - loss: 7210829801664282624.0000 - precision_m: 0.0177 - recall_m: 0.0176\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0174 - loss: 7027797949279109120.0000 - precision_m: 0.0175 - recall_m: 0.0174\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0173 - loss: 6854751861497397248.0000 - precision_m: 0.0174 - recall_m: 0.0173\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0172 - loss: 6690902638726217728.0000 - precision_m: 0.0173 - recall_m: 0.0172\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0171 - loss: 6535536697919143936.0000 - precision_m: 0.0172 - recall_m: 0.0171\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0170 - loss: 6388006976483229696.0000 - precision_m: 0.0171 - recall_m: 0.0170\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0169 - loss: 6180144303252176896.0000 - precision_m: 0.0170 - recall_m: 0.0169\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0168 - loss: 6049768612477009920.0000 - precision_m: 0.0169 - recall_m: 0.0168\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0167 - loss: 5925412198108102656.0000 - precision_m: 0.0168 - recall_m: 0.0167\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0167 - loss: 5806658345238528000.0000 - precision_m: 0.0168 - recall_m: 0.0167\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0166 - loss: 5693128272112517120.0000 - precision_m: 0.0167 - recall_m: 0.0166\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0166 - loss: 5584475082811506688.0000 - precision_m: 0.0166 - recall_m: 0.0166\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0165 - loss: 5480382667742511104.0000 - precision_m: 0.0166 - recall_m: 0.0165\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0165 - loss: 5380561305591611392.0000 - precision_m: 0.0166 - recall_m: 0.0165\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0164 - loss: 5284746014056513536.0000 - precision_m: 0.0165 - recall_m: 0.0164\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0164 - loss: 5192692701555851264.0000 - precision_m: 0.0165 - recall_m: 0.0164\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0164 - loss: 5104176517961744384.0000 - precision_m: 0.0164 - recall_m: 0.0164\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0163 - loss: 5018990755088171008.0000 - precision_m: 0.0164 - recall_m: 0.0163\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0163 - loss: 4936945197423525888.0000 - precision_m: 0.0164 - recall_m: 0.0163\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0163 - loss: 4857862273839923200.0000 - precision_m: 0.0163 - recall_m: 0.0163\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0162 - loss: 4781579256616452096.0000 - precision_m: 0.0163 - recall_m: 0.0162\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0162 - loss: 4707944413148479488.0000 - precision_m: 0.0162 - recall_m: 0.0162\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0162 - loss: 4636817555703463936.0000 - precision_m: 0.0162 - recall_m: 0.0162\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0161 - loss: 4568067567519793152.0000 - precision_m: 0.0162 - recall_m: 0.0161\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0161 - loss: 4501573227440504832.0000 - precision_m: 0.0162 - recall_m: 0.0161\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0161 - loss: 4437220736012124160.0000 - precision_m: 0.0162 - recall_m: 0.0161\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0161 - loss: 4374904540118384640.0000 - precision_m: 0.0162 - recall_m: 0.0161\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0161 - loss: 4344551971877814272.0000 - precision_m: 0.0161 - recall_m: 0.0161\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 78ms/step - accuracy: 0.0161 - loss: 4314812381369729024.0000 - precision_m: 0.0161 - recall_m: 0.0161 - val_accuracy: 0.0128 - val_loss: 39475788.0000 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - loss: 15963302.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/25\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 39777428.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m13/25\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0043 - loss: 40861640.0000 - precision_m: 0.0043 - recall_m: 0.0043            \n",
            "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0090 - loss: 39583088.0000 - precision_m: 0.0090 - recall_m: 0.0090\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0102 - loss: 39674428.0000 - precision_m: 0.0102 - recall_m: 0.0102\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0103 - loss: 39666788.0000 - precision_m: 0.0103 - recall_m: 0.0103\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:55\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 118.1812 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 10507106910208.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0013 - loss: 8370456625152.0000 - precision_m: 0.0018 - recall_m: 0.0013             \n",
            "\u001b[1m14/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0036 - loss: 6642257100800.0000 - precision_m: 0.0051 - recall_m: 0.0032\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0058 - loss: 5545628532736.0000 - precision_m: 0.0062 - recall_m: 0.0039\n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0070 - loss: 4787613990912.0000 - precision_m: 0.0063 - recall_m: 0.0039\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0076 - loss: 4229715722240.0000 - precision_m: 0.0062 - recall_m: 0.0039\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0080 - loss: 3800094998528.0000 - precision_m: 0.0060 - recall_m: 0.0037\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0083 - loss: 3457895628800.0000 - precision_m: 0.0058 - recall_m: 0.0036\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0086 - loss: 3178132144128.0000 - precision_m: 0.0056 - recall_m: 0.0034\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0088 - loss: 2944630784000.0000 - precision_m: 0.0053 - recall_m: 0.0033\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0090 - loss: 2746435764224.0000 - precision_m: 0.0051 - recall_m: 0.0031\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0091 - loss: 2575847915520.0000 - precision_m: 0.0049 - recall_m: 0.0030\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0091 - loss: 2427287764992.0000 - precision_m: 0.0047 - recall_m: 0.0029\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0092 - loss: 2296608456704.0000 - precision_m: 0.0045 - recall_m: 0.0028\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0092 - loss: 2180658626560.0000 - precision_m: 0.0044 - recall_m: 0.0027\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0092 - loss: 2076998500352.0000 - precision_m: 0.0042 - recall_m: 0.0026\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0092 - loss: 1983707348992.0000 - precision_m: 0.0041 - recall_m: 0.0025\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0093 - loss: 1899251761152.0000 - precision_m: 0.0040 - recall_m: 0.0024\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0093 - loss: 1822391402496.0000 - precision_m: 0.0038 - recall_m: 0.0024\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0093 - loss: 1765705777152.0000 - precision_m: 0.0037 - recall_m: 0.0023\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.0094 - loss: 1752199200768.0000 - precision_m: 0.0037 - recall_m: 0.0023 - val_accuracy: 0.0128 - val_loss: 4.4405 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 4.1996 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m12/25\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0331 - loss: 4.4244 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00     \n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0258 - loss: 4.4213 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0243 - loss: 4.4237 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:23\u001b[0m 6s/step - accuracy: 0.0000e+00 - loss: 4.3554 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 6/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0032 - loss: 6.2140 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00     \n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0034 - loss: 6.5947 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0044 - loss: 6.6159 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0046 - loss: 6.5614 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0046 - loss: 6.4903 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0050 - loss: 6.4059 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0055 - loss: 6.3415 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0058 - loss: 6.2882 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0061 - loss: 6.2323 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0064 - loss: 6.1837 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0067 - loss: 6.1416 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0070 - loss: 6.1034 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0073 - loss: 6.0675 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0076 - loss: 6.0350 - precision_m: 1.3235e-05 - recall_m: 1.0340e-05\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0079 - loss: 6.0108 - precision_m: 4.2195e-05 - recall_m: 3.2965e-05\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0081 - loss: 5.9844 - precision_m: 7.0538e-05 - recall_m: 5.5107e-05\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0083 - loss: 5.9639 - precision_m: 8.9918e-05 - recall_m: 7.0248e-05\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.0084 - loss: 5.9482 - precision_m: 1.0317e-04 - recall_m: 8.0600e-05\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.0085 - loss: 5.9444 - precision_m: 1.0625e-04 - recall_m: 8.3007e-05 - val_accuracy: 0.0128 - val_loss: 5.6958 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 6.5706 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 5.9800 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0031 - loss: 5.8428 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0050 - loss: 5.8106 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:18\u001b[0m 6s/step - accuracy: 0.0312 - loss: 133.8982 - precision_m: 0.0312 - recall_m: 0.0312\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0171 - loss: 55249448960.0000 - precision_m: 0.0171 - recall_m: 0.0171\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0159 - loss: 57100976128.0000 - precision_m: 0.0159 - recall_m: 0.0159\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0158 - loss: 51302330368.0000 - precision_m: 0.0158 - recall_m: 0.0158\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0150 - loss: 45881741312.0000 - precision_m: 0.0150 - recall_m: 0.0150\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0140 - loss: 41414225920.0000 - precision_m: 0.0140 - recall_m: 0.0140\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0134 - loss: 37762924544.0000 - precision_m: 0.0134 - recall_m: 0.0134\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0128 - loss: 34744807424.0000 - precision_m: 0.0128 - recall_m: 0.0128\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0122 - loss: 32213477376.0000 - precision_m: 0.0122 - recall_m: 0.0122\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0118 - loss: 30060431360.0000 - precision_m: 0.0118 - recall_m: 0.0118\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0114 - loss: 28205924352.0000 - precision_m: 0.0114 - recall_m: 0.0114\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0112 - loss: 26590750720.0000 - precision_m: 0.0112 - recall_m: 0.0112\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0110 - loss: 25170296832.0000 - precision_m: 0.0110 - recall_m: 0.0110\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0108 - loss: 23910397952.0000 - precision_m: 0.0108 - recall_m: 0.0108\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0107 - loss: 22784712704.0000 - precision_m: 0.0107 - recall_m: 0.0107\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0106 - loss: 21772003328.0000 - precision_m: 0.0106 - recall_m: 0.0106\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0106 - loss: 20855588864.0000 - precision_m: 0.0106 - recall_m: 0.0106\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0105 - loss: 20021817344.0000 - precision_m: 0.0105 - recall_m: 0.0105\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0105 - loss: 19259600896.0000 - precision_m: 0.0105 - recall_m: 0.0105\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0104 - loss: 18559778816.0000 - precision_m: 0.0104 - recall_m: 0.0104\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0103 - loss: 17914824704.0000 - precision_m: 0.0103 - recall_m: 0.0103\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0103 - loss: 17318230016.0000 - precision_m: 0.0103 - recall_m: 0.0103\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0103 - loss: 16764519424.0000 - precision_m: 0.0103 - recall_m: 0.0103\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0103 - loss: 16249056256.0000 - precision_m: 0.0103 - recall_m: 0.0103\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0102 - loss: 15767864320.0000 - precision_m: 0.0102 - recall_m: 0.0102\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0102 - loss: 15652741120.0000 - precision_m: 0.0102 - recall_m: 0.0102\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.0102 - loss: 15539943424.0000 - precision_m: 0.0102 - recall_m: 0.0102 - val_accuracy: 0.0128 - val_loss: 6084821.5000 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 13788146.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m10/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 9012860.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00  \n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0104 - loss: 7771082.0000 - precision_m: 0.0104 - recall_m: 0.0104            \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0112 - loss: 7391025.5000 - precision_m: 0.0111 - recall_m: 0.0111\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:15\u001b[0m 4s/step - accuracy: 0.0625 - loss: 4.3555 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.0469 - loss: 4.6110 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.0394 - loss: 4.7790 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.0350 - loss: 4.8789 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.0326 - loss: 4.9308 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.0312 - loss: 4.9710 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.0303 - loss: 4.9983 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.0291 - loss: 5.0128 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.0279 - loss: 5.0284 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.0269 - loss: 5.0409 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.0260 - loss: 5.0525 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.0252 - loss: 5.0619 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0245 - loss: 5.0691 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0240 - loss: 5.0742 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0236 - loss: 5.0774 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0233 - loss: 5.0798 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0230 - loss: 5.0814 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0227 - loss: 5.0817 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0224 - loss: 5.0813 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0221 - loss: 5.0799 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0218 - loss: 5.0781 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0215 - loss: 5.0761 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0213 - loss: 5.0741 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0211 - loss: 5.0718 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0209 - loss: 5.0694 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0207 - loss: 5.0676 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0205 - loss: 5.0657 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0204 - loss: 5.0639 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0202 - loss: 5.0621 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0200 - loss: 5.0601 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0198 - loss: 5.0578 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0197 - loss: 5.0553 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0196 - loss: 5.0531 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0195 - loss: 5.0508 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.0194 - loss: 5.0484 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0193 - loss: 5.0461 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0191 - loss: 5.0437 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0190 - loss: 5.0413 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0189 - loss: 5.0391 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0188 - loss: 5.0370 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0187 - loss: 5.0348 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0186 - loss: 5.0326 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0185 - loss: 5.0305 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0184 - loss: 5.0283 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0183 - loss: 5.0261 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0182 - loss: 5.0241 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0181 - loss: 5.0222 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0180 - loss: 5.0204 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0180 - loss: 5.0186 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.0179 - loss: 5.0177 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 85ms/step - accuracy: 0.0179 - loss: 5.0168 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.6920 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - loss: 4.5932 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 6/25\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 4.5667 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 4.6043 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0025 - loss: 4.6345 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0059 - loss: 4.6490 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0073 - loss: 4.6562 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:29\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 51.3048 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 832835158016.0000 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0053 - loss: 769559953408.0000 - precision_m: 0.0062 - recall_m: 0.0053            \n",
            "\u001b[1m 8/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0084 - loss: 643836215296.0000 - precision_m: 0.0098 - recall_m: 0.0084\n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0092 - loss: 550570622976.0000 - precision_m: 0.0130 - recall_m: 0.0092\n",
            "\u001b[1m14/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0102 - loss: 482212020224.0000 - precision_m: 0.0171 - recall_m: 0.0102\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0105 - loss: 430273200128.0000 - precision_m: 0.0188 - recall_m: 0.0105\n",
            "\u001b[1m20/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0104 - loss: 389447876608.0000 - precision_m: 0.0194 - recall_m: 0.0104\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0104 - loss: 356452139008.0000 - precision_m: 0.0194 - recall_m: 0.0101\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0103 - loss: 329176743936.0000 - precision_m: 0.0192 - recall_m: 0.0098\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0104 - loss: 306211356672.0000 - precision_m: 0.0188 - recall_m: 0.0095\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0104 - loss: 286578180096.0000 - precision_m: 0.0184 - recall_m: 0.0092\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0104 - loss: 269577764864.0000 - precision_m: 0.0179 - recall_m: 0.0089\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0103 - loss: 254696226816.0000 - precision_m: 0.0174 - recall_m: 0.0086\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0103 - loss: 241547132928.0000 - precision_m: 0.0169 - recall_m: 0.0083\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0103 - loss: 229834113024.0000 - precision_m: 0.0164 - recall_m: 0.0080\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0104 - loss: 219325808640.0000 - precision_m: 0.0160 - recall_m: 0.0078\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0104 - loss: 209838817280.0000 - precision_m: 0.0155 - recall_m: 0.0075\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0105 - loss: 201225846784.0000 - precision_m: 0.0151 - recall_m: 0.0073\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0106 - loss: 193367097344.0000 - precision_m: 0.0147 - recall_m: 0.0071\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0108 - loss: 186164051968.0000 - precision_m: 0.0144 - recall_m: 0.0069\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0109 - loss: 179534987264.0000 - precision_m: 0.0140 - recall_m: 0.0067\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0110 - loss: 173411450880.0000 - precision_m: 0.0137 - recall_m: 0.0065\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0112 - loss: 167735623680.0000 - precision_m: 0.0134 - recall_m: 0.0064\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0113 - loss: 162458353664.0000 - precision_m: 0.0131 - recall_m: 0.0062\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0115 - loss: 157537599488.0000 - precision_m: 0.0128 - recall_m: 0.0061\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0117 - loss: 152937086976.0000 - precision_m: 0.0125 - recall_m: 0.0059\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0118 - loss: 148625391616.0000 - precision_m: 0.0122 - recall_m: 0.0058\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0119 - loss: 144575201280.0000 - precision_m: 0.0120 - recall_m: 0.0057\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0120 - loss: 140762529792.0000 - precision_m: 0.0117 - recall_m: 0.0055\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0121 - loss: 137166364672.0000 - precision_m: 0.0115 - recall_m: 0.0054\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0122 - loss: 133768085504.0000 - precision_m: 0.0113 - recall_m: 0.0053\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0123 - loss: 130551218176.0000 - precision_m: 0.0111 - recall_m: 0.0052\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.0124 - loss: 127502696448.0000 - precision_m: 0.0109 - recall_m: 0.0051\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 71ms/step - accuracy: 0.0125 - loss: 126525423616.0000 - precision_m: 0.0108 - recall_m: 0.0051 - val_accuracy: 0.0128 - val_loss: 4.4308 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - loss: 4.3609 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/25\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 4.4918 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m13/25\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 4.5053 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0049 - loss: 4.4912 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0071 - loss: 4.4774 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0073 - loss: 4.4756 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:50\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0129 - loss: 4.3555 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0118 - loss: 4.3551 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0116 - loss: 4.3562 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0131 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: 4.3583 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: 4.3588 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: 4.3591 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: 4.3594 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: 4.3597 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: 4.3599 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: 4.3602 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0136 - loss: 4.3604 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0135 - loss: 4.3607 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0133 - loss: 4.3610 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: 4.3613 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0130 - loss: 4.3615 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0128 - loss: 4.3618 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0126 - loss: 4.3621 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0125 - loss: 4.3623 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0123 - loss: 4.3626 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.0123 - loss: 4.3626 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3571 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 4.3721 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/25\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 4.3528 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0052 - loss: 4.3527 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0080 - loss: 4.3536 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:29\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 4.4795 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 8/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0059 - loss: 337.0458 - precision_m: 0.0060 - recall_m: 0.0059           \n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0067 - loss: 515.8810 - precision_m: 0.0068 - recall_m: 0.0067\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0074 - loss: 605.9579 - precision_m: 0.0075 - recall_m: 0.0074\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0080 - loss: 662.8369 - precision_m: 0.0081 - recall_m: 0.0080\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0084 - loss: 703.4468 - precision_m: 0.0085 - recall_m: 0.0084\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0086 - loss: 735.2465 - precision_m: 0.0087 - recall_m: 0.0086\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0090 - loss: 764.2621 - precision_m: 0.0090 - recall_m: 0.0090\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0092 - loss: 788.8239 - precision_m: 0.0093 - recall_m: 0.0092\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0094 - loss: 809.5347 - precision_m: 0.0094 - recall_m: 0.0094\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0095 - loss: 826.2038 - precision_m: 0.0096 - recall_m: 0.0095\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0096 - loss: 835.5577 - precision_m: 0.0096 - recall_m: 0.0096\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0096 - loss: 841.6252 - precision_m: 0.0097 - recall_m: 0.0096\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0097 - loss: 845.1287 - precision_m: 0.0097 - recall_m: 0.0097\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.0097 - loss: 845.4628 - precision_m: 0.0097 - recall_m: 0.0097 - val_accuracy: 0.0128 - val_loss: 907.5565 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 493.7212 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0483 - loss: 743.5645 - precision_m: 0.0483 - recall_m: 0.0483             \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0344 - loss: 807.3914 - precision_m: 0.0343 - recall_m: 0.0343\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:38\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 4.9993 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 6/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: 7.3477 - precision_m: 0.0021 - recall_m: 8.6806e-04        \n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0110 - loss: 11.7857 - precision_m: 0.0064 - recall_m: 0.0032   \n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0119 - loss: 17.0211 - precision_m: 0.0085 - recall_m: 0.0051\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0126 - loss: 21.0610 - precision_m: 0.0100 - recall_m: 0.0068\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0126 - loss: 24.0178 - precision_m: 0.0105 - recall_m: 0.0075\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0123 - loss: 26.7351 - precision_m: 0.0106 - recall_m: 0.0077\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0119 - loss: 28.8565 - precision_m: 0.0104 - recall_m: 0.0077\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0117 - loss: 31.0650 - precision_m: 0.0104 - recall_m: 0.0078\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0114 - loss: 33.7664 - precision_m: 0.0103 - recall_m: 0.0078\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0111 - loss: 36.0241 - precision_m: 0.0101 - recall_m: 0.0077\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0108 - loss: 38.6450 - precision_m: 0.0099 - recall_m: 0.0076\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0107 - loss: 40.6566 - precision_m: 0.0099 - recall_m: 0.0077\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0107 - loss: 42.4503 - precision_m: 0.0100 - recall_m: 0.0079\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0108 - loss: 44.0668 - precision_m: 0.0101 - recall_m: 0.0080\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0108 - loss: 45.5177 - precision_m: 0.0102 - recall_m: 0.0082\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0109 - loss: 46.8405 - precision_m: 0.0103 - recall_m: 0.0084\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0110 - loss: 48.0308 - precision_m: 0.0105 - recall_m: 0.0085\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0110 - loss: 49.1215 - precision_m: 0.0106 - recall_m: 0.0087\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0111 - loss: 49.5312 - precision_m: 0.0106 - recall_m: 0.0087\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 89ms/step - accuracy: 0.0111 - loss: 49.7303 - precision_m: 0.0106 - recall_m: 0.0087 - val_accuracy: 0.0128 - val_loss: 78.6188 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 82.3588 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0026 - loss: 89.1692 - precision_m: 0.0026 - recall_m: 0.0026             \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0107 - loss: 84.0688 - precision_m: 0.0107 - recall_m: 0.0107\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0112 - loss: 82.8773 - precision_m: 0.0111 - recall_m: 0.0111\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:49\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 32.8130 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0125 - loss: 1357634076672.0000 - precision_m: 0.0128 - recall_m: 0.0125 \n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0124 - loss: 1014024241152.0000 - precision_m: 0.0131 - recall_m: 0.0124\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0120 - loss: 815005696000.0000 - precision_m: 0.0116 - recall_m: 0.0109 \n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0118 - loss: 686612348928.0000 - precision_m: 0.0103 - recall_m: 0.0096 \n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0118 - loss: 596415283200.0000 - precision_m: 0.0092 - recall_m: 0.0086\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0115 - loss: 529216176128.0000 - precision_m: 0.0084 - recall_m: 0.0078\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0112 - loss: 476992995328.0000 - precision_m: 0.0077 - recall_m: 0.0071\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0111 - loss: 435103858688.0000 - precision_m: 0.0071 - recall_m: 0.0066\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0110 - loss: 400668491776.0000 - precision_m: 0.0066 - recall_m: 0.0061\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0109 - loss: 371800113152.0000 - precision_m: 0.0062 - recall_m: 0.0057\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0109 - loss: 347208089600.0000 - precision_m: 0.0058 - recall_m: 0.0054\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0108 - loss: 325977899008.0000 - precision_m: 0.0055 - recall_m: 0.0051\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0107 - loss: 307442417664.0000 - precision_m: 0.0052 - recall_m: 0.0048\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0106 - loss: 291102720000.0000 - precision_m: 0.0050 - recall_m: 0.0046\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0105 - loss: 276577878016.0000 - precision_m: 0.0048 - recall_m: 0.0044\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0104 - loss: 263571652608.0000 - precision_m: 0.0045 - recall_m: 0.0042\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0104 - loss: 261537759232.0000 - precision_m: 0.0045 - recall_m: 0.0042\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.0104 - loss: 259544940544.0000 - precision_m: 0.0045 - recall_m: 0.0041 - val_accuracy: 0.0128 - val_loss: 4.4951 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 4.4824 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m14/25\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0317 - loss: 4.4394 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00     \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0243 - loss: 4.4642 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:29\u001b[0m 4s/step - accuracy: 0.0312 - loss: 4.4705 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0191 - loss: 71.4688 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.0183 - loss: 165.2357 - precision_m: 0.0041 - recall_m: 0.0041       \n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0179 - loss: 233.9677 - precision_m: 0.0063 - recall_m: 0.0063\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0180 - loss: 286.2126 - precision_m: 0.0081 - recall_m: 0.0081\n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0182 - loss: 325.8688 - precision_m: 0.0096 - recall_m: 0.0096\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0187 - loss: 355.3969 - precision_m: 0.0110 - recall_m: 0.0110\n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0188 - loss: 378.9680 - precision_m: 0.0119 - recall_m: 0.0119\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0187 - loss: 398.6758 - precision_m: 0.0124 - recall_m: 0.0124\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0185 - loss: 414.8661 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0183 - loss: 430.0295 - precision_m: 0.0129 - recall_m: 0.0129\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0182 - loss: 443.4453 - precision_m: 0.0131 - recall_m: 0.0131\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0180 - loss: 455.4342 - precision_m: 0.0132 - recall_m: 0.0132\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0178 - loss: 466.2442 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0176 - loss: 476.0601 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0173 - loss: 485.3750 - precision_m: 0.0132 - recall_m: 0.0132\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0170 - loss: 493.9798 - precision_m: 0.0131 - recall_m: 0.0131\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0167 - loss: 501.7375 - precision_m: 0.0130 - recall_m: 0.0130\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0165 - loss: 508.5609 - precision_m: 0.0129 - recall_m: 0.0129\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0162 - loss: 514.9139 - precision_m: 0.0128 - recall_m: 0.0128\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0160 - loss: 520.7653 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0159 - loss: 526.0320 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0157 - loss: 531.0609 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 535.9096 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 540.3389 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 544.4252 - precision_m: 0.0128 - recall_m: 0.0128\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 548.2401 - precision_m: 0.0129 - recall_m: 0.0129\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 551.7847 - precision_m: 0.0130 - recall_m: 0.0130\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 555.0561 - precision_m: 0.0131 - recall_m: 0.0131\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 558.0280 - precision_m: 0.0132 - recall_m: 0.0132\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 560.8542 - precision_m: 0.0132 - recall_m: 0.0132\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 563.5164 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0156 - loss: 565.9410 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0155 - loss: 568.2057 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0155 - loss: 570.2988 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0154 - loss: 572.1428 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0153 - loss: 573.7249 - precision_m: 0.0133 - recall_m: 0.0133\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0153 - loss: 575.0838 - precision_m: 0.0132 - recall_m: 0.0132\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0152 - loss: 576.2008 - precision_m: 0.0132 - recall_m: 0.0132\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0151 - loss: 577.2210 - precision_m: 0.0132 - recall_m: 0.0132\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0150 - loss: 578.0947 - precision_m: 0.0131 - recall_m: 0.0131\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0149 - loss: 578.8533 - precision_m: 0.0131 - recall_m: 0.0131\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0149 - loss: 579.5178 - precision_m: 0.0130 - recall_m: 0.0130\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0148 - loss: 580.0823 - precision_m: 0.0129 - recall_m: 0.0129\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0147 - loss: 580.5616 - precision_m: 0.0129 - recall_m: 0.0129\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0146 - loss: 580.9878 - precision_m: 0.0128 - recall_m: 0.0128\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0145 - loss: 581.3849 - precision_m: 0.0128 - recall_m: 0.0128\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0144 - loss: 581.7905 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0143 - loss: 582.1303 - precision_m: 0.0127 - recall_m: 0.0127\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0143 - loss: 582.2863 - precision_m: 0.0126 - recall_m: 0.0126\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.0142 - loss: 582.4392 - precision_m: 0.0126 - recall_m: 0.0126 - val_accuracy: 0.0128 - val_loss: 398.7998 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 236.4469 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 6/25\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 341.1978 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m12/25\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 362.0818 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 370.0774 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0013 - loss: 375.1035 - precision_m: 0.0013 - recall_m: 0.0013            \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0027 - loss: 377.6723 - precision_m: 0.0026 - recall_m: 0.0026\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:47\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.3479 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 16.5777 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 22.9138 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 24.8565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0016 - loss: 25.6793 - precision_m: 0.0016 - recall_m: 0.0016            \n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0024 - loss: 26.2751 - precision_m: 0.0024 - recall_m: 0.0024\n",
            "\u001b[1m14/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0029 - loss: 27.7494 - precision_m: 0.0029 - recall_m: 0.0029\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0035 - loss: 29.6094 - precision_m: 0.0035 - recall_m: 0.0035\n",
            "\u001b[1m20/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0037 - loss: 31.3159 - precision_m: 0.0037 - recall_m: 0.0037\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0041 - loss: 32.8166 - precision_m: 0.0041 - recall_m: 0.0041\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0043 - loss: 34.1258 - precision_m: 0.0044 - recall_m: 0.0043\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0045 - loss: 35.3274 - precision_m: 0.0047 - recall_m: 0.0045\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0049 - loss: 36.4026 - precision_m: 0.0051 - recall_m: 0.0049\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0054 - loss: 37.4486 - precision_m: 0.0055 - recall_m: 0.0054\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0059 - loss: 38.4601 - precision_m: 0.0062 - recall_m: 0.0059\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0063 - loss: 39.4510 - precision_m: 0.0067 - recall_m: 0.0063\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0067 - loss: 40.4203 - precision_m: 0.0071 - recall_m: 0.0067\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0071 - loss: 41.4385 - precision_m: 0.0075 - recall_m: 0.0071\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0073 - loss: 42.4686 - precision_m: 0.0078 - recall_m: 0.0073\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0076 - loss: 43.4913 - precision_m: 0.0081 - recall_m: 0.0076\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0078 - loss: 44.4790 - precision_m: 0.0083 - recall_m: 0.0078\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0081 - loss: 45.4270 - precision_m: 0.0086 - recall_m: 0.0081\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0083 - loss: 46.3309 - precision_m: 0.0088 - recall_m: 0.0083\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0085 - loss: 47.1983 - precision_m: 0.0090 - recall_m: 0.0084\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0086 - loss: 48.0300 - precision_m: 0.0091 - recall_m: 0.0086\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0087 - loss: 48.5571 - precision_m: 0.0092 - recall_m: 0.0086\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0089 - loss: 49.3079 - precision_m: 0.0093 - recall_m: 0.0087\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0090 - loss: 49.9957 - precision_m: 0.0095 - recall_m: 0.0089\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0091 - loss: 50.6212 - precision_m: 0.0097 - recall_m: 0.0090\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0093 - loss: 51.1923 - precision_m: 0.0098 - recall_m: 0.0091\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0094 - loss: 51.7179 - precision_m: 0.0099 - recall_m: 0.0092\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0095 - loss: 52.2068 - precision_m: 0.0101 - recall_m: 0.0093\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0096 - loss: 52.6600 - precision_m: 0.0102 - recall_m: 0.0094\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0097 - loss: 53.0783 - precision_m: 0.0103 - recall_m: 0.0094\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0098 - loss: 53.4655 - precision_m: 0.0104 - recall_m: 0.0095\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0098 - loss: 53.5896 - precision_m: 0.0104 - recall_m: 0.0095\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.0099 - loss: 53.7112 - precision_m: 0.0105 - recall_m: 0.0095 - val_accuracy: 0.0128 - val_loss: 77.5107 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 79.2459 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/25\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0711 - loss: 71.5726 - precision_m: 0.0711 - recall_m: 0.0711            \n",
            "\u001b[1m13/25\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0524 - loss: 70.5124 - precision_m: 0.0524 - recall_m: 0.0524\n",
            "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0419 - loss: 71.1343 - precision_m: 0.0419 - recall_m: 0.0419\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0352 - loss: 72.6365 - precision_m: 0.0352 - recall_m: 0.0352 \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0344 - loss: 72.8240 - precision_m: 0.0343 - recall_m: 0.0343\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:18\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 6/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0028 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0076 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0092 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0102 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m12/25\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0025 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:54\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 4.8719 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 13.2985 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0016 - loss: 16.8351 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0030 - loss: 18.0568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0038 - loss: 18.7411 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0049 - loss: 19.2462 - precision_m: 7.8512e-04 - recall_m: 5.2985e-04\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0055 - loss: 19.5826 - precision_m: 0.0013 - recall_m: 8.7157e-04    \n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0064 - loss: 19.8772 - precision_m: 0.0022 - recall_m: 0.0014    \n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0074 - loss: 20.1046 - precision_m: 0.0030 - recall_m: 0.0019\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0081 - loss: 20.2331 - precision_m: 0.0038 - recall_m: 0.0024\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0086 - loss: 20.2685 - precision_m: 0.0043 - recall_m: 0.0027\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0089 - loss: 20.2440 - precision_m: 0.0046 - recall_m: 0.0029\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0090 - loss: 20.1593 - precision_m: 0.0048 - recall_m: 0.0030\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0092 - loss: 20.0249 - precision_m: 0.0051 - recall_m: 0.0031\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: 19.8611 - precision_m: 0.0054 - recall_m: 0.0032\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 19.6797 - precision_m: 0.0055 - recall_m: 0.0033\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0096 - loss: 19.4897 - precision_m: 0.0058 - recall_m: 0.0033\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: 19.2933 - precision_m: 0.0060 - recall_m: 0.0034\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: 19.0928 - precision_m: 0.0061 - recall_m: 0.0034\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: 18.8885 - precision_m: 0.0062 - recall_m: 0.0034\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: 18.6833 - precision_m: 0.0063 - recall_m: 0.0034\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0100 - loss: 18.5612 - precision_m: 0.0063 - recall_m: 0.0034\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.0100 - loss: 18.5216 - precision_m: 0.0063 - recall_m: 0.0034 - val_accuracy: 0.0128 - val_loss: 7.5317 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 10.4178 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 8.8038 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00  \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 8.2686 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0015 - loss: 8.1376 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:16\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 77.5900 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 4/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0046 - loss: 62006087680.0000 - precision_m: 0.0046 - recall_m: 0.0046    \n",
            "\u001b[1m 8/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0052 - loss: 85982879744.0000 - precision_m: 0.0052 - recall_m: 0.0052\n",
            "\u001b[1m12/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0067 - loss: 80026148864.0000 - precision_m: 0.0067 - recall_m: 0.0067\n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0073 - loss: 72283914240.0000 - precision_m: 0.0074 - recall_m: 0.0073\n",
            "\u001b[1m20/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0076 - loss: 65499742208.0000 - precision_m: 0.0076 - recall_m: 0.0076\n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0076 - loss: 59834077184.0000 - precision_m: 0.0077 - recall_m: 0.0076\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0078 - loss: 55105159168.0000 - precision_m: 0.0078 - recall_m: 0.0078\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0079 - loss: 51118981120.0000 - precision_m: 0.0080 - recall_m: 0.0079\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0082 - loss: 47718875136.0000 - precision_m: 0.0083 - recall_m: 0.0082\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0084 - loss: 44785233920.0000 - precision_m: 0.0085 - recall_m: 0.0084\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0086 - loss: 42227470336.0000 - precision_m: 0.0087 - recall_m: 0.0086\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0088 - loss: 39976501248.0000 - precision_m: 0.0088 - recall_m: 0.0088\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0089 - loss: 37979029504.0000 - precision_m: 0.0089 - recall_m: 0.0089\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0089 - loss: 36193406976.0000 - precision_m: 0.0090 - recall_m: 0.0089\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0090 - loss: 34586648576.0000 - precision_m: 0.0091 - recall_m: 0.0090\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0090 - loss: 33132339200.0000 - precision_m: 0.0091 - recall_m: 0.0090\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0091 - loss: 31809054720.0000 - precision_m: 0.0092 - recall_m: 0.0091\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0091 - loss: 30599256064.0000 - precision_m: 0.0093 - recall_m: 0.0091\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0092 - loss: 29488443392.0000 - precision_m: 0.0093 - recall_m: 0.0092\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0093 - loss: 28464510976.0000 - precision_m: 0.0094 - recall_m: 0.0093\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 27517288448.0000 - precision_m: 0.0095 - recall_m: 0.0094\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0095 - loss: 26638149632.0000 - precision_m: 0.0096 - recall_m: 0.0095\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0096 - loss: 25819742208.0000 - precision_m: 0.0098 - recall_m: 0.0096\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0097 - loss: 25055748096.0000 - precision_m: 0.0099 - recall_m: 0.0097\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0098 - loss: 24692799488.0000 - precision_m: 0.0099 - recall_m: 0.0098\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.0098 - loss: 24516636672.0000 - precision_m: 0.0100 - recall_m: 0.0098 - val_accuracy: 0.0128 - val_loss: 62.4749 - val_precision_m: 0.0125 - val_recall_m: 0.0125\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 53.7619 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m10/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0105 - loss: 52.6896 - precision_m: 0.0105 - recall_m: 0.0105             \n",
            "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0157 - loss: 60.2529 - precision_m: 0.0157 - recall_m: 0.0157\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0152 - loss: 61.1519 - precision_m: 0.0152 - recall_m: 0.0152\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.012500000186264515\n",
            "validation precision: 0.012500000186264515\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:29\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.4828 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 3/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 13.2865 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 21.6834 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 30.0551 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - loss: 37.8273 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 5.4236e-04 - loss: 44.8408 - precision_m: 5.4236e-04 - recall_m: 5.4236e-04\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0012 - loss: 51.6971 - precision_m: 0.0012 - recall_m: 0.0012            \n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0016 - loss: 58.0906 - precision_m: 0.0016 - recall_m: 0.0016\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0021 - loss: 63.9925 - precision_m: 0.0021 - recall_m: 0.0021\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0025 - loss: 69.4442 - precision_m: 0.0025 - recall_m: 0.0025\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0031 - loss: 74.3918 - precision_m: 0.0031 - recall_m: 0.0031\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0036 - loss: 78.7613 - precision_m: 0.0036 - recall_m: 0.0036\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0040 - loss: 82.8506 - precision_m: 0.0040 - recall_m: 0.0040\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0044 - loss: 86.6424 - precision_m: 0.0044 - recall_m: 0.0044\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0048 - loss: 90.1095 - precision_m: 0.0048 - recall_m: 0.0048\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0051 - loss: 93.2293 - precision_m: 0.0051 - recall_m: 0.0051\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0053 - loss: 96.0346 - precision_m: 0.0053 - recall_m: 0.0053\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0055 - loss: 98.5240 - precision_m: 0.0055 - recall_m: 0.0055\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0056 - loss: 100.8129 - precision_m: 0.0056 - recall_m: 0.0056\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0057 - loss: 102.9042 - precision_m: 0.0057 - recall_m: 0.0057\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0057 - loss: 104.7758 - precision_m: 0.0058 - recall_m: 0.0057\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0058 - loss: 106.5070 - precision_m: 0.0058 - recall_m: 0.0058\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0059 - loss: 108.0568 - precision_m: 0.0059 - recall_m: 0.0059\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0060 - loss: 109.4608 - precision_m: 0.0060 - recall_m: 0.0060\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0060 - loss: 110.6902 - precision_m: 0.0060 - recall_m: 0.0060\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0061 - loss: 111.7681 - precision_m: 0.0061 - recall_m: 0.0061\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0062 - loss: 112.7322 - precision_m: 0.0062 - recall_m: 0.0062\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0062 - loss: 113.5794 - precision_m: 0.0063 - recall_m: 0.0062\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0063 - loss: 114.3042 - precision_m: 0.0064 - recall_m: 0.0063\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0064 - loss: 114.9349 - precision_m: 0.0065 - recall_m: 0.0064\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0065 - loss: 115.4585 - precision_m: 0.0066 - recall_m: 0.0065\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0066 - loss: 115.9002 - precision_m: 0.0067 - recall_m: 0.0066\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0067 - loss: 116.2746 - precision_m: 0.0067 - recall_m: 0.0067\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0068 - loss: 116.5710 - precision_m: 0.0068 - recall_m: 0.0068\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0068 - loss: 116.7996 - precision_m: 0.0069 - recall_m: 0.0068\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0069 - loss: 116.9666 - precision_m: 0.0070 - recall_m: 0.0069\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0070 - loss: 117.0789 - precision_m: 0.0071 - recall_m: 0.0070\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0071 - loss: 117.1498 - precision_m: 0.0072 - recall_m: 0.0071\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0072 - loss: 117.1829 - precision_m: 0.0073 - recall_m: 0.0072\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0073 - loss: 117.1796 - precision_m: 0.0073 - recall_m: 0.0073\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0074 - loss: 117.1406 - precision_m: 0.0074 - recall_m: 0.0074\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0075 - loss: 117.0730 - precision_m: 0.0075 - recall_m: 0.0075\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0075 - loss: 116.9812 - precision_m: 0.0076 - recall_m: 0.0075\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0077 - loss: 116.8696 - precision_m: 0.0077 - recall_m: 0.0077\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0078 - loss: 116.7360 - precision_m: 0.0078 - recall_m: 0.0078\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0079 - loss: 116.5847 - precision_m: 0.0079 - recall_m: 0.0079\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0080 - loss: 116.4183 - precision_m: 0.0080 - recall_m: 0.0080\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0080 - loss: 116.2356 - precision_m: 0.0081 - recall_m: 0.0080\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0081 - loss: 116.0443 - precision_m: 0.0082 - recall_m: 0.0081\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.0082 - loss: 115.9473 - precision_m: 0.0083 - recall_m: 0.0082\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.0082 - loss: 115.8523 - precision_m: 0.0083 - recall_m: 0.0082 - val_accuracy: 0.0128 - val_loss: 55.2704 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 25.2251 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 6/25\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 48.2930 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 52.9738 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 55.0623 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0015 - loss: 56.3491 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0037 - loss: 56.3333 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:15\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 4/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0104 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0111 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m10/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0120 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0116 - loss: 4.3572 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0113 - loss: 4.3572 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0112 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0115 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0116 - loss: 4.3575 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0116 - loss: 4.3577 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0116 - loss: 4.3578 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0115 - loss: 4.3578 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0114 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0112 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0112 - loss: 4.3580 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0111 - loss: 4.3580 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0111 - loss: 4.3581 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0110 - loss: 4.3581 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0110 - loss: 4.3582 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0109 - loss: 4.3582 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0108 - loss: 4.3583 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0107 - loss: 4.3583 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0107 - loss: 4.3584 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0107 - loss: 4.3584 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0107 - loss: 4.3585 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0106 - loss: 4.3585 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0106 - loss: 4.3586 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0105 - loss: 4.3587 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0105 - loss: 4.3587 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0104 - loss: 4.3588 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0103 - loss: 4.3588 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0102 - loss: 4.3589 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0101 - loss: 4.3589 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0101 - loss: 4.3590 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.0101 - loss: 4.3590 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3567 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/25\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0031 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:32\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 4.3559 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 4/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m10/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.8491e-04 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 8.4130e-04 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0022 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0031 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0038 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0044 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0049 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0055 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0059 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0063 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0067 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0069 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0072 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0075 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0077 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0079 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0081 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0083 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0085 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0087 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0088 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0090 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0090 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - accuracy: 0.0090 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3567 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 4.3548 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/25\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0035 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0071 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0073 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:20\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0134 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0133 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0251 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0237 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0214 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0193 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0180 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0173 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0166 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0159 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0028 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0038 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0058 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0071 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0080 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0086 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0100 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0102 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0104 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0089 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0083 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0084 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0121 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0133 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0134 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0126 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:10\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0061 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:22\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0121 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:38\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0028 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0038 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0049 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0062 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0070 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0077 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0081 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0088 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0102 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0104 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m10/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.8125e-04 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:58\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 4/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0085 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0121 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m10/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0127 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0122 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0115 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m20/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0105 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0104 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0105 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0106 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0105 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0105 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0104 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0103 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0102 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0102 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.0102 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3567 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 4.3575 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/25\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0037 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:09\u001b[0m 4s/step - accuracy: 0.0938 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0441 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0349 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0317 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0297 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0273 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0255 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0244 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0234 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0227 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0221 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0216 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0211 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0207 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0203 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0199 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0195 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0191 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0188 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0184 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0181 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0181 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.0180 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:13\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0049 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0046 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m14/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0051 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0062 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0067 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0070 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0073 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0076 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0080 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0082 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0085 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0088 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0100 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0101 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0102 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0189 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0198 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0195 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0193 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0189 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0185 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0180 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0178 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0178 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0177 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0176 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0175 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0173 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0171 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0169 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0167 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0166 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0164 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0134 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0134 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0133 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0133 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:21\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0092 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:20\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0134 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0126 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0125 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0123 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0123 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0123 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0122 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0122 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0122 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0122 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0077 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0089 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0165 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0165 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0164 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:52\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 4/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0013 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m11/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0041 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m15/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0050 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0055 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0061 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0065 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0067 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0069 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0071 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0072 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0074 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0075 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0075 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0077 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0078 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0079 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0081 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0081 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0082 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0083 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0083 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0084 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0084 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0085 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.0085 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3567 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 4.3593 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/25\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 4.3577 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0068 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0093 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0095 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0235 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0191 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0175 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0049 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0054 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0055 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0067 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0075 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0082 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0121 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0126 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0128 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:13\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0019 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0030 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0032 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0038 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0043 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0045 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0045 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0048 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0050 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0053 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0055 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0057 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0059 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0061 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0063 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0065 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0067 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0069 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0072 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0073 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0074 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:19\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0088 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0101 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0104 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0272 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0227 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0200 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0193 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0182 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0177 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0175 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0171 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0167 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0163 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0223 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0104 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0092 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0092 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0100 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0101 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0102 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:20\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0061 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m14/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:13\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0180 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0180 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0167 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0134 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 4.9797 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 5.7732 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 8.1983e-04 - loss: 5.8588 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0020 - loss: 5.8508 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0025 - loss: 5.8224 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0036 - loss: 5.7792 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0043 - loss: 5.7376 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0048 - loss: 5.7047 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0052 - loss: 5.6747 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0055 - loss: 5.6467 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0058 - loss: 5.6161 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0060 - loss: 5.5930 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0064 - loss: 5.5719 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0066 - loss: 5.5526 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0068 - loss: 5.5352 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0070 - loss: 5.5189 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0071 - loss: 5.5035 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0071 - loss: 5.4890 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0072 - loss: 5.4750 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0073 - loss: 5.4617 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0074 - loss: 5.4464 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0075 - loss: 5.4322 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0076 - loss: 5.4192 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0077 - loss: 5.4119 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0077 - loss: 5.4095 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3916 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 4.2221 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0266 - loss: 4.3091 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00     \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0232 - loss: 4.3356 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0213 - loss: 4.3457 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0185 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0200 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0189 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0176 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0165 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0104 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0092 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0096 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0100 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0102 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:17\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0012 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0072 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0179 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0173 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0166 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0300 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0255 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0229 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0208 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0191 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0177 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0166 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0159 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:19\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0014 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0027 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0035 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0044 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0054 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0062 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0069 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0075 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0080 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0084 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0088 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0100 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0100 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0284 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0246 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0223 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0204 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0189 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0178 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0171 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0164 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0135 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:13\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 2.6780e-04 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 6.8266e-04 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0013 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0019 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0023 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0027 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0031 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0035 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0038 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0043 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0047 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0051 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0054 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0058 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0061 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0065 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0065 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.0066 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:25\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0133 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0128 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0352 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0271 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m14/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0215 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0188 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0169 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0143 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0223 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0181 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0165 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0146 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0141 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:23\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0128 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0132 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0131 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0182 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0195 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0187 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0182 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0177 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0173 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0170 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0167 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0164 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0159 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0028 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0057 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0065 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0068 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0068 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0068 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0070 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0073 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0078 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0080 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0082 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0085 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0086 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0088 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0093 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0095 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0096 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0098 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0049 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0046 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0046 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0061 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0077 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0102 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0105 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0107 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0219 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0235 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0221 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0207 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0178 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0172 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0168 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0165 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0164 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0163 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:54\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.3575 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 4/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0150 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0154 - loss: 4.3572 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m10/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0159 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0165 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0165 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0162 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0157 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0150 - loss: 4.3572 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0145 - loss: 4.3572 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0140 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0135 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0131 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0127 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0123 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0120 - loss: 4.3575 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0117 - loss: 4.3575 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0115 - loss: 4.3576 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0112 - loss: 4.3576 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0110 - loss: 4.3576 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0108 - loss: 4.3577 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0107 - loss: 4.3577 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0105 - loss: 4.3578 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0103 - loss: 4.3578 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0101 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0100 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0099 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.0098 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3567 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/25\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 4.3576 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0040 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0044 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:19\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 3.3115e-04 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0011 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0019 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0028 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0042 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0046 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0051 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0057 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0062 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0066 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0071 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0074 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0077 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0081 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0084 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0086 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0087 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0087 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:20\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0129 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0121 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0122 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0123 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m10/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 7.8125e-04 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0080 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0077 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0078 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m18/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0081 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0082 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m28/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0084 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m33/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0088 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m38/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0091 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m48/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m53/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0099 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m58/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0101 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m68/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m73/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0104 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m78/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0109 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:19\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 4.5956 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 4.7638 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0021 - loss: 4.7591 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00    \n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0046 - loss: 4.7420 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0062 - loss: 4.7243 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0069 - loss: 4.7089 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0071 - loss: 4.6968 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0074 - loss: 4.6838 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0076 - loss: 4.6731 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0079 - loss: 4.6621 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0081 - loss: 4.6525 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0082 - loss: 4.6440 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0082 - loss: 4.6358 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.6285 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.6223 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.6168 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.6126 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.6077 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.6032 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.5990 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0083 - loss: 4.5952 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0083 - loss: 4.5922 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - accuracy: 0.0083 - loss: 4.5915 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3888 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 4.6375 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0162 - loss: 4.4607 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00     \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0178 - loss: 4.4352 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0169 - loss: 4.4277 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0019 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0023 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0029 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0040 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0052 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0064 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0075 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0084 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0092 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0097 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0101 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0103 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0108 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0112 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0171 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0133 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0126 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0127 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0124 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0241 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0207 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0200 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0190 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0175 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0134 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0130 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0128 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0126 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0125 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0123 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0122 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0120 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0118 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0119 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0049 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0046 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0046 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0059 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0074 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0085 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0090 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0100 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0106 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0110 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0111 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0113 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0114 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0115 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0116 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.0117 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0223 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0166 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m25/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m30/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0162 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m40/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m45/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m50/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m60/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m65/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m70/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m80/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m85/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0136 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0182 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0188 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0185 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0180 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0173 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0166 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0147 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0144 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0142 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0140 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0139 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0138 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0137 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0178 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0207 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0208 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0197 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0185 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0176 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m32/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0174 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m37/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0171 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m42/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0168 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0165 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m52/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0163 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m57/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m62/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0158 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m72/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0155 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m77/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m82/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0328 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0326 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m14/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0311 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0288 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m24/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0270 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m29/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0252 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m34/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0238 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0229 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m44/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0221 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m49/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0214 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m54/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0207 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0201 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m64/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0196 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m69/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m74/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0189 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0185 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m84/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0182 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0180 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0178 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0176 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0175 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:56\u001b[0m 4s/step - accuracy: 0.0312 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 4/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0247 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 7/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0255 - loss: 4.3564 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m10/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0231 - loss: 4.3564 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0218 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m16/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0211 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0205 - loss: 4.3567 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m23/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0198 - loss: 4.3568 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m27/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0191 - loss: 4.3569 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0184 - loss: 4.3570 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m35/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0179 - loss: 4.3571 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m39/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0174 - loss: 4.3572 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m43/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0169 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m47/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0165 - loss: 4.3573 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0160 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m55/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0157 - loss: 4.3574 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m59/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0153 - loss: 4.3575 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m63/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0150 - loss: 4.3575 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m67/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0147 - loss: 4.3576 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0144 - loss: 4.3577 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m75/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0142 - loss: 4.3577 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m79/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0139 - loss: 4.3578 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m83/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0137 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0135 - loss: 4.3579 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0132 - loss: 4.3580 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0130 - loss: 4.3581 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0129 - loss: 4.3581 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.0128 - loss: 4.3581 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_accuracy: 0.0128 - val_loss: 4.3567 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 4.3589 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m 9/25\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0189 - loss: 4.3566 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00     \n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0213 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0192 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0189 - loss: 4.3565 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: 0.0\n",
            "validation precision: 0.0\n",
            "\u001b[1m 1/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 3s/step - accuracy: 0.0312 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 5/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0192 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m 9/98\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0166 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m13/98\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0171 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m17/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0174 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m21/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0172 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m26/98\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0169 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m31/98\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0165 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m36/98\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0161 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m41/98\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m46/98\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0160 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m51/98\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0159 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m56/98\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0159 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m61/98\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0157 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m66/98\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0156 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m71/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0154 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m76/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0153 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m81/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0152 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m86/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0151 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0150 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0149 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0148 - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.0128 - val_loss: nan - val_precision_m: nan - val_recall_m: nan\n",
            "\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - precision_m: nan - recall_m: nan \n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0015 - loss: nan - precision_m: nan - recall_m: nan    \n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0037 - loss: nan - precision_m: nan - recall_m: nan\n",
            "\n",
            "validation Accuracy: 0.012820512987673283\n",
            "validation recall: nan\n",
            "validation precision: nan\n",
            " 40%|████      | 81/200 [14:30<18:23,  9.27s/trial, best loss: 4.3567118644714355]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:hyperopt.fmin:job exception: Graph execution error:\n",
            "\n",
            "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "\n",
            "  File \"<ipython-input-41-49e25ec3cf03>\", line 1, in <cell line: 0>\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 540, in fmin\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\", line 671, in fmin\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 586, in fmin\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 364, in exhaust\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 300, in run\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 178, in serial_evaluate\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\", line 892, in evaluate\n",
            "\n",
            "  File \"<ipython-input-39-2873d6883313>\", line 60, in create_model\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n",
            "\n",
            "Out of memory while trying to allocate 1544345752 bytes.\n",
            "\t [[{{node StatefulPartitionedCall}}]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
            " [Op:__inference_multi_step_on_iterator_284430]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 81/200 [14:43<21:38, 10.91s/trial, best loss: 4.3567118644714355]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-41-49e25ec3cf03>\", line 1, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 540, in fmin\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\", line 671, in fmin\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 586, in fmin\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 364, in exhaust\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 300, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 178, in serial_evaluate\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\", line 892, in evaluate\n\n  File \"<ipython-input-39-2873d6883313>\", line 60, in create_model\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nOut of memory while trying to allocate 1544345752 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_284430]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-49e25ec3cf03>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m best_params = fmin(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#bayesian optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#number of models to try\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-2873d6883313>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     58\u001b[0m                                                       patience=3)\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     model.fit(train_images, train_name_enc,\n\u001b[0m\u001b[1;32m     61\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_name_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m               callbacks=[early_stopping])\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-41-49e25ec3cf03>\", line 1, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 540, in fmin\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\", line 671, in fmin\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 586, in fmin\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 364, in exhaust\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 300, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\", line 178, in serial_evaluate\n\n  File \"/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\", line 892, in evaluate\n\n  File \"<ipython-input-39-2873d6883313>\", line 60, in create_model\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nOut of memory while trying to allocate 1544345752 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_284430]"
          ]
        }
      ],
      "source": [
        "best_params = fmin(\n",
        "    fn = create_model,\n",
        "    space = params_space,\n",
        "    algo = tpe.suggest, #bayesian optimization\n",
        "    max_evals= 200, #number of models to try\n",
        "    trials= trial,\n",
        "    batch_size =32,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently the best model is not performing well so it is best to change model and use a pretriained one"
      ],
      "metadata": {
        "id": "C5G4m5qkps9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space_eval(params_space, best_params)"
      ],
      "metadata": {
        "id": "SueP75EbMr81"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}